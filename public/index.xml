<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Index on temperancee&#39;s website</title>
    <link>/</link>
    <description>temperancee&#39;s website (Index)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    
      

      
    

    
    <lastBuildDate>Mon, 21 Jul 2025 21:50:13 +0100</lastBuildDate>
    
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Diy Quadcopter</title>
      <link>/projects/diy_quadcopter/</link>
      <pubDate>Wed, 22 Oct 2025 16:37:02 +0100</pubDate>
      
      <guid>/projects/diy_quadcopter/</guid>
      <description>&lt;p&gt;This page documents my attempt at building a quadcopter from scratch. This includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Designing my own PCB in KiCAD&lt;/li&gt;
&lt;li&gt;Programming the ESP32S3 microcontroller on the PCB to interact with the IMU&lt;/li&gt;
&lt;li&gt;Writing a driver for said IMU in C using FreeRTOS&lt;/li&gt;
&lt;li&gt;Implementing a Kalman Filter in C using FreeRTOS to fuse the accelerometer and gyroscope data from the IMU into usable Euler angles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, this project is not complete, as I lost interest in it and switched over to working on my &lt;a href=&#34;http://localhost:1313/projects/robot_arm/&#34;&gt;robot arm&lt;/a&gt;. I did however enjoy working on the PCB design, learning about the Kalman Filter, and using FreeRTOS, so I wanted to document my work here.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Repository: &lt;a href=&#34;https://github.com/temperancee/wayfinder&#34;&gt;Wayfinder&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Like my robot arm, this project comprises many parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Kalman filter&lt;/li&gt;
&lt;li&gt;The PCB design&lt;/li&gt;
&lt;li&gt;The (very simple) driver&lt;/li&gt;
&lt;li&gt;FreeRTOS considerations&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;&#34;&gt;Sensor Fusion and the Kalman Filter&lt;/h2&gt;
&lt;p&gt;The goal of this section is simply to stabilise the quadcopter in the air, so it can hover. We can think about this as fixing the roll and pitch angles of the quadcopter to 0. Roll, pitch, and yaw angles tell us how much a body in 3D space has been rotated around each of the x, y, and z axes, as in the diagram below:&lt;/p&gt;
&lt;p&gt;We will refer to these angles as Euler angles throughout this article, although technically they are not necessarily the same - see &lt;a href=&#34;https://en.wikipedia.org/wiki/Euler_angles&#34;&gt;Euler Angles&lt;/a&gt; for more details.
We seek a way to measure the roll and pitch angles. We ignore the yaw, as we just want the drone to hover, and don&amp;rsquo;t particularly care which way it faces (and from a more practical standpoint, measuring yaw requires a &lt;a href=&#34;https://en.wikipedia.org/wiki/Magnetometer&#34;&gt;magnetometer&lt;/a&gt;, which are tricky to use, and make the drone more expensive than I need it to be). The sensor we use for this is the Intertial Measurement Unit (IMU), which is a combination of a gyroscope and an accelerometer (more expensive IMUs also include magnetometers, in which case they are called 9-axis IMUs, whereas a gyroscope accelerometer combo is a 6-axis IMU). The gyroscope measures angular &lt;em&gt;velocity&lt;/em&gt;, and the accelerometer measures acceleration in the x, y, and z directions. These are of course, not what we want, but with a bit of maths we can turn both of these measurements into measurements of roll and pitch.&lt;/p&gt;
&lt;h3 id=&#34;&#34;&gt;Deriving roll and pitch from the accelerometer and gyroscope&lt;/h3&gt;
&lt;p&gt;Angular velocity is just the rate of change of our Euler angles, so by integrating the angular velocity of roll and pitch, we get our desired angles. We use Euler integration for this, leading us to the expression $$\phi_t = \phi_{t-1} + \phi^\prime_t\Delta t$$ where $\phi_t$ is the roll at time $t$, $\phi^\prime_t$ is the rate of change of the roll at time $t$ (this is what the gyroscope outputs), and $\Delta t$ is the time between each iteration (more on this later). We have the same equation for our pitch, $\theta$.&lt;/p&gt;
&lt;p&gt;The accelerometer measurements &amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;&#34;&gt;The problem&lt;/h3&gt;
&lt;h3 id=&#34;&#34;&gt;Hidden Markov Models and the Bayes Filter&lt;/h3&gt;
&lt;p&gt;Hidden Markov Models (HMM) can be used to model partially observable processes that evolve over time. By this we mean there are some unobserved random variables $X_t$ which we are interested in, but cannot observe, called the &lt;em&gt;latent&lt;/em&gt; variables, and observable variables $Y_t$ which depend on $X_t$ called measurement variables. We wish to make inferences about $X_t$ but only have access to $Y_t$, which may be, for example, measurements of $X_t$ corrupted by noise. A key property of the HMM is that $$\mathbb{P}(X_t = x_t | X_{t-1} = x_{t-1}, &amp;hellip;, X_0 = x_0) = \mathbb{P}(X_t = x_t | X_{t-1} = x_{t-1})$$ that is, the probability of being in a particular state at time $t$ depends only on the previous state.&lt;/p&gt;
&lt;p&gt;In our case, the $x_t = \begin{pmatrix} \phi &amp;amp; \theta \end{pmatrix}^T$ are our &lt;em&gt;state&lt;/em&gt;, the variables that characterise the state of our quadcopter (i.e., we only care about roll and pitch, so that is all that is included in the state, but if we cared about yaw, or x, y, z coordinates, those too would feature). We will discuss what exactly we model $y_t$ as in our situation a bit further down the line.&lt;/p&gt;
&lt;p&gt;For Hidden Markov Models that model sequential processes, we can predict the next state given our previous state estimate and the current measurement, $y_t$, using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation&#34;&gt;Bayes Filter&lt;/a&gt;. I am not going to go into details of the derivation, which can be found in Probabilistic Robotics by Sebastian Thrun. The gist is that using a model of how our previous state $x_{t-1} and a control chosen at time $t$, $u_t$, affect $x_t$, we update our beliefs about $x_t$. The control here, $u_t$ is a way that we can influence the state, for example, by increasing the speed of our drones propellers, we can make it move around. The second step in the Bayes Filter is to incorporate the measurement information $y_t$ into our beliefs. Through this process, we can estimate the next state, in our case, our roll and pitch angles.&lt;/p&gt;
&lt;h3 id=&#34;&#34;&gt;The Kalman Filter&lt;/h3&gt;
&lt;p&gt;What model should we use for how our measurment affects state and how previous state and control affects state? There are many answers to this, but one of the simplest ones is the Kalman Filter. The Kalman Filter assumes a linear relationship between the next state and the previous state and the control, with Gaussian noise. It also assumes a linear relationship between the state and measurment, again with Gaussian noise. This allows us to derive an analytical solution for the update rules given by the Bayes Filter, whereas in almost all other cases, the integrals we have to compute are intractable.&lt;/p&gt;
&lt;p&gt;We specify that $$x_t = A_t x_{t-1} + B_t u_t + \epsilon_t$$&lt;/p&gt;
&lt;p&gt;Another point of note is that the state is not something we can observe directly, we can only attempt to measure it via the accelerometer and gyroscope, which are &lt;em&gt;noisy&lt;/em&gt;, i.e., there is some random error associated with the measurements they give us. In this way, the Kalman Filter is an analogue of a Hidden Markov Model, except our latent variables (the hidden ones, in this case, the roll and pitch) are on a continuous state space, rather than a discrete one as is the case with a HMM (I think).&lt;/p&gt;
&lt;p&gt;Formally, we assume that the&lt;/p&gt;
&lt;p&gt;In this context, our state is the roll and pitch of the quadcopter. These two variables sit together in a 2D vector in our equations. We cannot model the yaw of the quadcopter, because this would require a magnetometer, but fortunately, we can make do with just pitch and yaw for the purposes of making the quadcopter hover and move through the air (which was the original goal for this project).&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The PCB design&lt;/h2&gt;
&lt;p&gt;I designed the PCB for the flight computer in KiCAD. Learning PCB design took a long time. I found the videos by Phil&amp;rsquo;s Lab on YouTube to be an invaluable source of knowledge. I learnt about the importance of trace widths, layers, stitching vias, (just list all the somewhat advanced things you had to learn).&lt;/p&gt;
&lt;p&gt;I also revisited some basic electronic knowledge when trying to understand the unidirectional motor circuits I used [picture]. This involved learning about MOSFETs and some basics on inductors (including flyback diodes).&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The driver&lt;/h2&gt;
&lt;p&gt;The IMU I chose to use for this project did not have a readily available Arduino driver written for it, so I endeavoured to read the data sheet and write a very minimal one myself. This was my first time writing a driver, and I found working at such a low-level of programming to be quite cool. The driver simply implements read and write functions for the IMU&amp;rsquo;s registers, an initialisation function which writes to some configuration registers on start-up, and a FreeRTOS task to read sensor data from the IMU&amp;rsquo;s accelerometer and gyroscope registers, transforming the acceleration and Euler angle rate of change units and updating the IMU struct variable with the new data (via a mutex, to protect the object from being read by another task).&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;FreeRTOS&lt;/h2&gt;
&lt;p&gt;In order to have the Kalman Filter and the planned PID loop run at the same time, I decided to use a real time operating system (RTOS) to handle scheduling the different tasks. I chose to use FreeRTOS for its simplicity, as this use case did not require a large suite of libraries like those offered by Zephyr for example. I learnt about mutexes, semaphores, queues, and timers - mutexes and timers especially were key to making sure the angle state was handled correctly, and that the Kalman Filter steps ran at the right time. This series of &lt;a href=&#34;https://www.youtube.com/playlist?list=PLUWXFeSM9LNTBX4GoapiTk_Kxs8FOPv0W&#34;&gt;videos by Shawn Hymel&lt;/a&gt; made the topic very clear and provided exercises to make sure I understood the material. I also learnt about notifications in FreeRTOS, which I used to replace the binary semaphores that were previously in my code.&lt;/p&gt;
&lt;h1 id=&#34;&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;While I abandoned this project in the end it was very fun to work on and taught me more than any previous project I had attempted. I found that I enjoyed working with FreeRTOS and writing low-level drivers, even if it made the programming side of things more complicated. Finally getting the opportunity to learn PCB design properly was great, and I reckon it will serve me well in the future, although I will try my best to avoid needing a bespoke PCB, since it did take a lot of time and effort, and it isn&amp;rsquo;t exactly cheap to get boards produced!&lt;/p&gt;
&lt;p&gt;When my next term of university begins at the start of 2026 I&amp;rsquo;ll be working on a self-balancing two-wheeled robot with another student from the Robotics Society at my university. It will require me to use my knowledge of Kalman Filters again, and will give me another opportunity to  implement a PID loop (I promise I&amp;rsquo;ll actually stick with it this time). Expect a post about that a few months from now.&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robot Arm</title>
      <link>/projects/robot_arm/</link>
      <pubDate>Fri, 15 Aug 2025 09:08:42 +0100</pubDate>
      
      <guid>/projects/robot_arm/</guid>
      <description>&lt;p&gt;This page documents my work on building a robot arm. At a glance this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deriving the inverse kinematics equations for a 5DOF robot arm, and implementing them in simulation and on hardware, handling various edge cases and hardware limitations&lt;/li&gt;
&lt;li&gt;Writing a simulator in matplotlib for not only the 5DOF arm but also a 6DOF arm&lt;/li&gt;
&lt;li&gt;Designing the arm in FreeCAD and 3D printing it&lt;/li&gt;
&lt;li&gt;Using a Raspberry Pi Pico W to control the servo motors and communicate with the web server&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Repositories: &lt;a href=&#34;https://github.com/temperancee/robot_arm&#34;&gt;Robot Arm&lt;/a&gt;, &lt;a href=&#34;https://github.com/temperancee/robot_arm_kinematics_simulation&#34;&gt;Simulation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;div class=&#34;pair-figure-shortcode&#34;&gt;
        &lt;figure&gt;
            &lt;video width=&#34;500&#34; height=&#34;600&#34;
                    muted
                    loop
                    autoplay
                controls&gt;
                &lt;source src=&#34;wrist_robot_arm.mp4&#34; type=&#34;video/mp4&#34;&gt; There is a video here, but your browser does not support the video tag.
            &lt;/video&gt;&lt;figcaption&gt;The robot can reach the same point from multiple orientations&lt;/figcaption&gt;
        &lt;/figure&gt;
        &lt;figure&gt;
            &lt;video width=&#34;500&#34; height=&#34;600&#34;
                    muted
                    loop
                    autoplay
                controls&gt;
                &lt;source src=&#34;square_robot_arm.mp4&#34; type=&#34;video/mp4&#34;&gt;
            There is a video here, but your browser does not support the video tag.
            &lt;/video&gt;&lt;figcaption&gt;The robot maps out a square using inverse kinematics&lt;/figcaption&gt;
        &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;This project can be split into seven parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The kinematics&lt;/li&gt;
&lt;li&gt;The simulation&lt;/li&gt;
&lt;li&gt;The CAD&lt;/li&gt;
&lt;li&gt;The electronics&lt;/li&gt;
&lt;li&gt;The Pico program&lt;/li&gt;
&lt;li&gt;The server program&lt;/li&gt;
&lt;li&gt;The web interface&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;&#34;&gt;Some terminology&lt;/h2&gt;
&lt;p&gt;I refer to &amp;rsquo;links&amp;rsquo; and &amp;lsquo;joints&amp;rsquo; throughout this article - joints are the servo motors (i.e., the things that make the parts of the arm rotate (although, more generally, joints do not have to be rotational)), and links are the things that hold the joints together.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The kinematics&lt;/h2&gt;
&lt;p&gt;I learnt forward and inverse kinematics by reading chapters 2, 3, and 5 of Robot Modelling and Control by Spong, Hutchinson, and Vidyasagar. It&amp;rsquo;s a pretty good book, but doesn&amp;rsquo;t give away all the answers. The book focuses on the case of a 6DOF robot arm with a spherical wrist, which is one of the robots I added to my simulation, but the 5DOF case is slightly different. My 5DOF robot does not have the first joint in the spherical wrist, which essentially means the wrist cannot yaw independently of the base of the robot. This limits the orientations of the end-effector, but not their positions, and for many tasks, this is fine. It meant that I had to calculate the yaw as a function of the base angle, and then use the 6DOF solution. Various other edge cases and limitations, such as the fact that my robot&amp;rsquo;s motors only rotate between 0 and 180 degrees, rather than a full 360, had to be accounted for in the code.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The simulation&lt;/h2&gt;
&lt;p&gt;The simulation program uses matplotlib to plot lines representing the links of the robot arm, as well as the coordinate frames of each joint. This was my first time writing a non-trivial object-oriented program, and I learnt lots about classes in Python and structuring code in general. It makes use of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller&#34;&gt;model-view-controller&lt;/a&gt; pattern, which keeps the code nice and organised.&lt;/p&gt;
&lt;p&gt;The simulation inclues options for simulating a 3DOF elbow manipulator, which forms the basis for the 5DOF and 6DOF manipulators, as well as the two more involved options. Below are videos of the 5 and 6DOF manipulators. You can see that the difference between the two is that the wrist cannot yaw independently of the &amp;ldquo;shoulder&amp;rdquo; of the arm in the 5DOF case, which as you can see in the video, results in the 5DOF arm being more limited in its choice of orientation for a given point (the yaw is coupled to the angle of the shoulder).&lt;/p&gt;
&lt;div class=&#34;pair-figure-shortcode&#34;&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/5DOF_manipulator_sim_hu_78178a460bca635c.gif&#34; width=&#34;400&#34; height=&#34;300&#34; alt=&#34;The 5DOF arm&#34;&gt;
            &lt;figcaption&gt;The 5DOF arm&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/6DOF_manipulator_sim_hu_b0378b94b31dea2c.gif&#34; width=&#34;400&#34; height=&#34;300&#34; alt2=&#34;The 6DOF arm&#34;&gt;
            &lt;figcaption&gt;The 6DOF arm&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&#34;&#34;&gt;The CAD&lt;/h2&gt;
&lt;p&gt;The robot was designed using FreeCAD. I designed all the parts myself. While the robot works, there are a lot of things I would have done differently if I were to start over:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Most importantly, the robot is very unstable. This was my first CAD design where knowledge of mechanical design techniques (which I possess very little of) played an important role. If I was to start over, I would like to buy some better motors, ideally ones where you can connect both sides of the motor to a joint. Since I wanted this first project to be cheap, this was sort of a necessary drawback.&lt;/li&gt;
&lt;li&gt;The shoulder joint was designed to just slot into the base, this means there is a lot of wiggle, so the positions taken by the model are often off by a couple of millimetres.&lt;/li&gt;
&lt;li&gt;The claw placement currently does not follow the Denavitt-Hartenberg convention. This was not a problem, until I implemented inverse kinematics. What it means in practice is that the claw position is always slightly off from the desired position. For this reason, there aren&amp;rsquo;t any videos of the robot actually picking anything up in this article.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;pair-figure-shortcode&#34;&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/robot_arm_cad_model_hu_376a5dc76479bc70.png&#34; width=&#34;400&#34; height=&#34;400&#34; alt=&#34;CAD model of the robot arm&#34;&gt;
            &lt;figcaption&gt;CAD model of the robot arm&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/robot_arm_cad_model_alt_pos_hu_2e8fb6b295fcb0a.png&#34; width=&#34;400&#34; height=&#34;400&#34; alt2=&#34;CAD model of the robot in a different position&#34;&gt;
            &lt;figcaption&gt;CAD model of the robot in a different position&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&#34;&#34;&gt;The electronics&lt;/h2&gt;
&lt;p&gt;The electronics in this project are very simple. The robot is controlled by a Raspberry Pi Pico W which connects to a PCA9685 servo driver board via I2C. The four MG99R servos and the one MG90s servo motor are connected to and controlled by this servo driver. The Pico receives joint angles from my PC via USB, then sends the angles to the servo driver, which then moves the servos. All the wiring lives on a breadboard.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The Pico program&lt;/h2&gt;
&lt;p&gt;The Pico code is written in Micropython. Originally, both cores on the Pico were utilised, courtesy of the &lt;a href=&#34;https://docs.micropython.org/en/latest/library/_thread.html&#34;&gt;_thread&lt;/a&gt; library. Servo control was handled by core0 and networking (for communication with the server (my PC)) was handled by core1. Servo control was implemented as a callback that activated every time servo angles were sent from the server. Long polling was used: The Pico sent a HTTP GET request for angles to the server, and the server responds when they are updated. Unfortunately, this wasn&amp;rsquo;t the most reliable form of communication, and it included lots of overhead. I wanted to simplify the process using Websockets rather than long polling, but couldn&amp;rsquo;t find any decent libraries that allowed to Pico to use Websockets while acting as a client, and my networking knowledge is limited to the point where I didn&amp;rsquo;t want to write my own.&lt;/p&gt;
&lt;p&gt;My solution came in the form of an even further simplification. Since my robot and server are always next to each other anyway, I simply chose to send servo angles from my PC to the Pico over USB, using &lt;a href=&#34;https://pythonhosted.org/pyserial/&#34;&gt;pyserial&lt;/a&gt;. This made the code on the Pico much simpler, and threading was no longer needed. Now the Pico simply waits for data to be received, then moves the servos accordingly via &lt;a href=&#34;https://github.com/kevinmcaleer/pca9685_for_pico&#34;&gt;Kevin McAleer&amp;rsquo;s micropython PCA9685 library&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The server&lt;/h2&gt;
&lt;p&gt;Originally, the server used the &lt;code&gt;ThreadingHTTPServer&lt;/code&gt; class from the &lt;a href=&#34;https://docs.python.org/3/library/http.server.html&#34;&gt;http.server&lt;/a&gt; library for communication with both the web interface and the Pico. As mentioned in the last section, the Pico now receives data via USB, and with this change I also moved to using the &lt;a href=&#34;https://microdot.readthedocs.io/en/latest/&#34;&gt;Microdot&lt;/a&gt; library for communication with the web interface. This makes the code a lot more readable by hiding away all the HTTP boilerplate.&lt;/p&gt;
&lt;p&gt;The server receives data from the web server: either angles or pose. Angles are immediately sent to the Pico, whereas pose data is first passed to the inverse kinematics method of the robot arm object, different arm configurations (e.g., elbow up vs elbow down) are checked for validity, and the resulting angles are sent over to the Pico, which then moves the servos.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The web interface&lt;/h2&gt;
&lt;p&gt;The front end of the web interface is an exceedingly basic HTML file, containing only 6 sliders (for angle and claw control), some text boxes to specify position and orientation and a few buttons to submit data. Maybe I&amp;rsquo;ll add some CSS in the future.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;As I mentioned in the CAD section, this robot, while functional, leaves a lot of room for improvement. This is of no surprise, since this was my first time building a robot, and I was bound to make mistakes. Nevertheless, I am due an upgrade. Over the course of this project, I most enjoyed working on the mathematics and programming side of things, as opposed to the CAD design and electronics. With that in mind, I have decided to build a &lt;a href=&#34;https://huggingface.co/docs/lerobot/so101&#34;&gt;LeRobot SO-101&lt;/a&gt; arm for the next stage of this project (and some future projects using reinforcement learning hopefully).&lt;/p&gt;
&lt;p&gt;The next stage is the addition of a camera to the workspace, which will run an object detection algorithm written in PyTorch - I&amp;rsquo;m currently learning about convolutional neural networks. I can then use my knowledge of rigid motions (learnt from Robot Modelling and Control) to determine the position of the objects detected in the camera frame to get their coordinates in the base frame, and move the robot accordingly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Micropython X Neovim</title>
      <link>/blog/micropython_x_neovim/</link>
      <pubDate>Tue, 08 Jul 2025 22:23:51 +0100</pubDate>
      
      <guid>/blog/micropython_x_neovim/</guid>
      <description>&lt;p&gt;This post teaches you how to get a barebones environment setup for working on Micropython projects with Neovim. This won&amp;rsquo;t cover setting up a proper Neovim environment, just how your can take an already well-developed environment and tailor it for Micropython development.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;Prerequistes&lt;/h2&gt;
&lt;p&gt;You should have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Neovim setup, I recommend TJ DeVries&amp;rsquo; &amp;ldquo;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLep05UYkc6wTyBe7kPjQFWVXTlhKeQejM&#34;&gt;Advent of Neovim&lt;/a&gt;&amp;rdquo; series for getting set up&lt;/li&gt;
&lt;li&gt;An understanding of LSPs in Neovim, again, see TJ DeVries&amp;rsquo; &lt;a href=&#34;https://youtu.be/bTWWFQZqzyI?si=ydv-dEtXykOh_cMh&#34;&gt;video&lt;/a&gt; on this&lt;/li&gt;
&lt;li&gt;An understanding of Python virtual environments, the &lt;a href=&#34;https://docs.python.org/3/library/venv.html&#34;&gt;docs&lt;/a&gt; are fairly accessible for this topic, or you can watch pretty much any YouTube video about venvs&lt;/li&gt;
&lt;li&gt;Basic familiarity with your shell (since this is a Neovim article, you probably know more than enough)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;&#34;&gt;Neovim LSP&lt;/h2&gt;
&lt;p&gt;There are many LSPs for Python, some of which you can read about by opening Neovim and running &lt;code&gt;:h lspconfig-all&lt;/code&gt;. I use Pyright, which works pretty well, and seems to be the most popular choice.&lt;/p&gt;
&lt;p&gt;If you use Mason, you can download it with that, or if you&amp;rsquo;re on Arch like me, a simple&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo pacman -S pyright
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;will suffice. For other operating systems, just use your standard package manager.&lt;/p&gt;
&lt;p&gt;You can also install Pyright via Pip if you&amp;rsquo;d like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install pyright
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we need to enable Pyright in our &lt;code&gt;init.lua&lt;/code&gt;, or alternative, a separate Lua file that we &lt;code&gt;require&lt;/code&gt; in &lt;code&gt;init.lua&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vim.lsp.enable(&lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#39;pyright&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run &lt;code&gt;:h lspconfig-all&lt;/code&gt; and read the Pyright section for details on configuring the LSP - for most use cases, just enabling Pyright should suffice.&lt;/p&gt;
&lt;h3 id=&#34;&#34;&gt;Micropython import errors, and stubs to the rescue&lt;/h3&gt;
&lt;p&gt;Micropython is mostly identical to the standard CPython implementation, just with some extra libraries added for working with microcontrollers, e.g. &lt;code&gt;machine&lt;/code&gt;.
These libraries exist on the device running Micropython, and so code that imports them runs fine.
However, when importing these libraries, we get errors in our editor, because these libraries don&amp;rsquo;t exist on our PC/Laptop, so our editor cannot see them.&lt;/p&gt;
&lt;p&gt;This is where stubs come in. Stubs are essentially files that implement all the classes, methods, functions, etc. in a library, but they leave the implementation empty. This allows your LSP to provide information on available functions and their parameters without you having to check the docs. It also gets rid of the import errors, as your system will now be able to see and recognise the Micropython libraries.&lt;/p&gt;
&lt;p&gt;Thankfully, there exists &lt;a href=&#34;https://github.com/Josverl/micropython-stubs&#34;&gt;a large repository of stubs for various micropython compatible boards&lt;/a&gt;, so we don&amp;rsquo;t have to create these files ourselves. Getting these stubs to work involves first installing them, then configuring Pyright to see them.&lt;/p&gt;
&lt;h4 id=&#34;&#34;&gt;Installation&lt;/h4&gt;
&lt;p&gt;We install the stubs with Pip, so you may have to create a virtual environment to use them (due to global Pip installs being forbidden by default in externally managed (i.e., by a package manager) environments - see &lt;a href=&#34;https://packaging.python.org/en/latest/specifications/externally-managed-environments/#externally-managed-environments&#34;&gt;this document&lt;/a&gt; for details).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python3 -m venv your-venv-name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#99d1db&#34;&gt;source&lt;/span&gt; your-venv-name/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These commands may differ depending on your operating system, see &lt;a href=&#34;https://docs.python.org/3/library/venv.html&#34;&gt;the docs&lt;/a&gt; for more details. Once the venv is created, we can either install the stubs directly, or create a &lt;code&gt;requirements-dev.txt&lt;/code&gt; file. We install the stubs to a folder called &lt;code&gt;typings&lt;/code&gt;.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#requirements-dev.txt
micropython-rp2-rpi_pico_w-stubs==1.25.0.*
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install -r requirements-dev.txt --target typings
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more detail, see the &lt;a href=&#34;https://micropython-stubs.readthedocs.io/en/main/11_install_stubs.html&#34;&gt;stubs documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;&#34;&gt;Configuring Pyright&lt;/h4&gt;
&lt;p&gt;Pyright is configured using either a &lt;code&gt;pyproject.toml&lt;/code&gt; or &lt;code&gt;pyrightconfig.json&lt;/code&gt; file. I use the toml file. There are various settings you can use to configure Pyright, documented &lt;a href=&#34;https://github.com/microsoft/pyright/blob/main/docs/configuration.md&#34;&gt;here&lt;/a&gt;. Here is my &lt;code&gt;pyproject.toml&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-toml&#34; data-lang=&#34;toml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[tool.pyright]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stubPath = &lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#34;typings&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;venvPath = &lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#34;.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;venv = &lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#34;micropython_venv&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;typeshedPath = &lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#34;typings&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;typeCheckingMode = &lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#34;basic&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;reportMissingModuleSource = &lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#34;none&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Firstly, we set the &lt;code&gt;stubPath&lt;/code&gt;, which tells Pyright where our stubs are stored.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;venvPath&lt;/code&gt; specifies a path to a directory which &lt;em&gt;contains&lt;/em&gt; virtual environments. Since my venv is in the same directory as my &lt;code&gt;pyproject.toml&lt;/code&gt;, I set this to the current directory.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;venv&lt;/code&gt; is used in conjunction with &lt;code&gt;venvPath&lt;/code&gt; to specify which venv to use for this project.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;typeshedPath&lt;/code&gt; is used to override the standard library stubs with the micropython ones. We set it to &lt;code&gt;&amp;quot;typings&amp;quot;&lt;/code&gt;, which is where our stubs are stored&lt;/li&gt;
&lt;li&gt;&lt;code&gt;typeCheckingMode&lt;/code&gt; does what it says on the tin. &lt;code&gt;&amp;quot;basic&amp;quot;&lt;/code&gt; should work for most people.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reportMissingModuleSource&lt;/code&gt; is a warning that appears when stubs are detected but their implementation files cannot be found. Since our implementation files are all stored on the device running MicroPython, we need to disable this warning.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All paths are relative to the root of the project. The root of the project is determined based on the &lt;code&gt;root-markers&lt;/code&gt; option set in your LSP configuration of Pyright. By default, this is &lt;code&gt;{ &amp;quot;pyproject.toml&amp;quot;, &amp;quot;setup.py&amp;quot;, &amp;quot;setup.cfg&amp;quot;, &amp;quot;requirements.txt&amp;quot;, &amp;quot;Pipfile&amp;quot;, &amp;quot;pyrightconfig.json&amp;quot;, &amp;quot;.git&amp;quot; }&lt;/code&gt;. I personally have mine set to the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vim.lsp.config(&lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#39;pyright&amp;#39;&lt;/span&gt;, {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    root&lt;span style=&#34;color:#99d1db;font-weight:bold&#34;&gt;-&lt;/span&gt;markers &lt;span style=&#34;color:#99d1db;font-weight:bold&#34;&gt;=&lt;/span&gt; { &lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#34;pyproject.toml&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#34;pyrightconfig.json&amp;#34;&lt;/span&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;})
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vim.lsp.enable(&lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#39;pyright&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more details on these settings and more, see both the &lt;a href=&#34;https://micropython-stubs.readthedocs.io/en/main/22_vscode.html&#34;&gt;stub documentation&lt;/a&gt; and the &lt;a href=&#34;https://github.com/microsoft/pyright/blob/main/docs/configuration.md&#34;&gt;Pyright documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And that&amp;rsquo;s it! The LSP should now be up and running, and you should be able to see information about imported classes, methods, etc.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;Micropython without Thonny/VSCode&lt;/h2&gt;
&lt;p&gt;Almost every Micropython tutorial you will see will simply tell you to install Thonny to upload code - if you&amp;rsquo;re lucky, they might show you how to use VSCode (although I&amp;rsquo;ve only seen this for RP2040 based boards). If you search for long enough, however, you may be lucky enough to learn about &lt;code&gt;rshell&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rshell&lt;/code&gt; is a command line utility that allows you to run commands on your board running Micropython. For full details, see its &lt;a href=&#34;https://github.com/dhylands/rshell&#34;&gt;github page&lt;/a&gt;. In this section, I&amp;rsquo;m just going to cover uploading and running files.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rshell&lt;/code&gt; is installed through &lt;code&gt;pip&lt;/code&gt;, which means we&amp;rsquo;ll need our venv again.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#99d1db&#34;&gt;source&lt;/span&gt; your-venv-name/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install rshell
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;&#34;&gt;Uploading Code&lt;/h3&gt;
&lt;p&gt;Micropython only runs programs on start-up when you copy them onto the board and name them &lt;code&gt;main.py&lt;/code&gt;. To accomplish this, open a terminal, make sure &lt;code&gt;rshell&lt;/code&gt; is installed (and, if necessary, make sure your &lt;code&gt;venv&lt;/code&gt; is active), then run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rshell -p /dev/ttyACM0
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which will put you into &lt;code&gt;rshell&lt;/code&gt;. Your board&amp;rsquo;s serial port might differ from &lt;code&gt;/dev/ttyACM0&lt;/code&gt;, in which case, change it accordingly.&lt;/p&gt;
&lt;p&gt;From here, we need to copy over our program to the board. Files on the board are stored under &lt;code&gt;/pyboard/&lt;/code&gt;, and you can see files on your system with &lt;code&gt;ls&lt;/code&gt;, just like in a normal shell. Bringing this together:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp my_program.py /pyboard/main.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And just like that, your program is on your board! Reset your board and it&amp;rsquo;ll start running.&lt;/p&gt;
&lt;h3 id=&#34;&#34;&gt;Using the REPL for debugging&lt;/h3&gt;
&lt;p&gt;I am not particularly well versed in the art of debugging tools - I&amp;rsquo;m still at the stage where print statements here and there typically get the job done. As such, this section is pretty much just dedicated to allowing you to see the printed output of your programs.&lt;/p&gt;
&lt;p&gt;We once again make use of &lt;code&gt;rshell&lt;/code&gt;. The trick here is to give your program an explicit main function. In Python, that is done via&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#c6d0f5;background-color:#303446;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ca9ee6&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#8caaee&#34;&gt;main&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#737994;font-style:italic&#34;&gt;# Your main function (doesn&amp;#39;t actually have to be called main)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ca9ee6&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f2d5cf&#34;&gt;__name__&lt;/span&gt; &lt;span style=&#34;color:#99d1db;font-weight:bold&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#a6d189&#34;&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    main()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This little snippet makes it so that &lt;code&gt;main()&lt;/code&gt; is run when you run your program. The benefit of this is that if someone imports your code, their namespace is not polluted with all of your global variables (which you can instead put inside main(), although, you needn&amp;rsquo;t put all your globals in there). There may also be other benefits, but I couldn&amp;rsquo;t find the PEP that outlines why it&amp;rsquo;s good to do this&amp;hellip;&lt;/p&gt;
&lt;p&gt;Anyway, for our purposes, the reason we do this is that it allows us to copy our code to &lt;code&gt;/pyboard/main.py&lt;/code&gt;, open up the &lt;code&gt;rshell&lt;/code&gt; REPL, and do the following:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;&amp;gt; from main import *
&amp;gt;&amp;gt; main()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;which will run our main function, and thus, the whole python script, directing ouputs into the REPL for us to see!&lt;/p&gt;
&lt;p&gt;You can also use this to run individual functions in your program, and see their output, which can similarly be helpful for debugging.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Wed, 18 Jun 2025 19:46:13 +0100</pubDate>
      
      <guid>/about/</guid>
      <description>&lt;p&gt;My name is Myles, I&amp;rsquo;m a fourth year mathematics and statistics student at Durham University with a strong interest in robotics and specifically computer vision applications in robotics. Last year I worked as an Operational Researcher in the Civil Service, helping to develop a static microsimulation model.&lt;/p&gt;
&lt;p&gt;On this website you can expect to find documentation of my projects, as well as some more general blog posts relating to programming, robotics, maths, and Linux, amongst other things.&lt;/p&gt;
&lt;p&gt;Enjoy your stay.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The classic first blog post, a note on this website</title>
      <link>/blog/this_website/</link>
      <pubDate>Mon, 16 Jun 2025 20:38:56 +0100</pubDate>
      
      <guid>/blog/this_website/</guid>
      <description>&lt;p&gt;A little spiel on how and why I made this website.&lt;/p&gt;
&lt;h1 id=&#34;&#34;&gt;A website! How?&lt;/h1&gt;
&lt;p&gt;With ease.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve made a personal website before actually. I crafted it out of raw html and css, no frameworks, or whatever, just as Tim Berners-Lee intended.&lt;/p&gt;
&lt;p&gt;$$ \frac{2}{3} $$&lt;/p&gt;
&lt;p&gt;This time around I wanted things to&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Just be plain easier to code, so I actually &lt;em&gt;use&lt;/em&gt; the damn thing&lt;/li&gt;
&lt;li&gt;Feel a bit more&amp;hellip; put together&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So I made this website using Hugo, the docs for which leave a &lt;em&gt;little&lt;/em&gt; to be desired in terms of a tutorial - it&amp;rsquo;s sort of like &amp;ldquo;so here&amp;rsquo;s how to install themes and make content - right! That&amp;rsquo;s all! Have fun wandering round the other doc pages slowly piecing everything else together!&amp;rdquo;. Whatever. I got it working easily enough.&lt;/p&gt;
&lt;p&gt;&lt;del&gt;Future me can pick this up, I might edit the CSS, which would certainly change the content of this article&lt;/del&gt;&lt;/p&gt;
&lt;h1 id=&#34;&#34;&gt;A website &amp;#x1f440;!? Why?&lt;/h1&gt;
&lt;p&gt;I needed a place to document my projects. I plan to make YouTube videos on them too, but videos are effort. Writing little posts is much easier (plus it acts as a sort of draft for the video script - two turds with one bone!).&lt;/p&gt;
&lt;p&gt;I also wanted a place to share some writings. Mini-essays of sorts. I realised I should write more - get the thoughts out there - &lt;em&gt;distill things&lt;/em&gt;. I&amp;rsquo;ve got a post coming up about teaching fractions, decimals, and division of them to children, motivated by my struggle trying to teach said topics to my little cousin.&lt;/p&gt;
&lt;p&gt;And finally, like the home page &lt;del&gt;says&lt;/del&gt; (will say):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;I ask, &amp;lsquo;cause I&amp;rsquo;m not sure, do anybody make real shit anymore?&amp;rdquo; - K. West, &lt;em&gt;Stronger&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Social media just ain&amp;rsquo;t got the &lt;strong&gt;vibe&lt;/strong&gt;. Same profile layout, same black background (because you&amp;rsquo;re not &lt;em&gt;seriously&lt;/em&gt; using Instagram in light mode are you?) - it&amp;rsquo;s a damn shame. That&amp;rsquo;s part of the reason I whacked this thing on &lt;a href=&#34;https://neocities.org/browse&#34;&gt;Neocities&lt;/a&gt; (also because it&amp;rsquo;s free): you see some real creativity from some real deranged people on there - &lt;em&gt;just as Tim Berners-Lee intended&lt;/em&gt;. Webpages should contain knowledge and vibes, not slop.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
