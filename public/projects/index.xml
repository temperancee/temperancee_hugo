<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on temperancee&#39;s website</title>
    <link>/projects/</link>
    <description>temperancee&#39;s website (Projects)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    
      

      
    

    
    <lastBuildDate>Wed, 22 Oct 2025 16:37:02 +0100</lastBuildDate>
    
    <atom:link href="/projects/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Diy Quadcopter</title>
      <link>/projects/diy_quadcopter/</link>
      <pubDate>Wed, 22 Oct 2025 16:37:02 +0100</pubDate>
      
      <guid>/projects/diy_quadcopter/</guid>
      <description>&lt;p&gt;This page documents my attempt at building a quadcopter from scratch. This includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Designing my own PCB in KiCAD&lt;/li&gt;
&lt;li&gt;Programming the ESP32S3 microcontroller on the PCB to interact with the IMU&lt;/li&gt;
&lt;li&gt;Writing a driver for said IMU in C using FreeRTOS&lt;/li&gt;
&lt;li&gt;Implementing a Kalman Filter in C using FreeRTOS to fuse the accelerometer and gyroscope data from the IMU into usable Euler angles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, this project is not complete, as I lost interest in it and switched over to working on my &lt;a href=&#34;http://localhost:1313/projects/robot_arm/&#34;&gt;robot arm&lt;/a&gt;. I did however enjoy working on the PCB design, learning about the Kalman Filter, and using FreeRTOS, so I wanted to document my work here.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Repository: &lt;a href=&#34;https://github.com/temperancee/wayfinder&#34;&gt;Wayfinder&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Like my robot arm, this project comprises many parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The PCB design&lt;/li&gt;
&lt;li&gt;The (very simple) driver&lt;/li&gt;
&lt;li&gt;The Kalman filter&lt;/li&gt;
&lt;li&gt;FreeRTOS considerations&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;&#34;&gt;The Kalman Filter&lt;/h2&gt;
&lt;p&gt;Something something $x_n = A_n x_{n+1} + B_n u_n + \epsilon$&lt;/p&gt;
&lt;p&gt;The setup is as follows: We want to get an estimate of the roll and pitch of our quadcopter at time step $n$. This will allow us to stabilise the drone in the air using a PID loop (which I never got around to implementing&amp;hellip;), which is just a way of making precise and thoughtful changes to our motor outputs to achieve the stability we desire. The problem arises in that the gyroscope in our IMU gives us measurements of the rate of change of each euler angle at a given moment. We can integrate these using Euler integration to get estimates for the angles themselves, but this estimate drifts further and further away from the true angle values over time, due to the Euler integration method summing all of our previous errors. Our accelerometer provides measurements of the accleration in the x, y, and z directions, which we can resolve into euler angles via trigonometry, but these estimates take a while to update&amp;hellip; or something. The solution is to fuse the two estimates together in order to produce a more accurate one.&lt;/p&gt;
&lt;p&gt;We seek a &lt;a href=&#34;https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation&#34;&gt;Bayes Filter&lt;/a&gt;, a method by which we can integrate new data (from our sensors) into our prior knowledge (about the state) in order to calculate our posterior knowledge about the state. Anybody familiar with Bayesian statistics will recognise that Bayes&amp;rsquo; rule would be perfect for this. We also construct a hidden Markov model - the actual state is hidden to us, but we can observe it through noisy measurements (from our sensors).&lt;/p&gt;
&lt;p&gt;In this context, our state is the roll and pitch of the quadcopter. These two variables sit together in a 2D vector in our equations. We cannot model the yaw of the quadcopter, because this would require a magnetometer, but fortunately, we can make do with just pitch and yaw for the purposes of making the quadcopter hover and move through the air (which was the original goal for this project).&lt;/p&gt;
&lt;p&gt;On the hill where nothing grows&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robot Arm</title>
      <link>/projects/robot_arm/</link>
      <pubDate>Fri, 15 Aug 2025 09:08:42 +0100</pubDate>
      
      <guid>/projects/robot_arm/</guid>
      <description>&lt;p&gt;This page documents my work on building a robot arm. At a glance this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deriving the inverse kinematics equations for a 5DOF robot arm, and implementing them in simulation and on hardware, handling various edge cases and hardware limitations&lt;/li&gt;
&lt;li&gt;Writing a simulator in matplotlib for not only the 5DOF arm but also a 6DOF arm&lt;/li&gt;
&lt;li&gt;Designing the arm in FreeCAD and 3D printing it&lt;/li&gt;
&lt;li&gt;Using a Raspberry Pi Pico W to control the servo motors and communicate with the web server&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Repositories: Robot Arm, &lt;a href=&#34;https://github.com/temperancee/robot_arm_kinematics_simulation&#34;&gt;Simulation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;div class=&#34;pair-figure-shortcode&#34;&gt;
        &lt;figure&gt;
            &lt;video width=&#34;500&#34; height=&#34;600&#34;
                    muted
                    loop
                    autoplay
                controls&gt;
                &lt;source src=&#34;wrist_robot_arm.mp4&#34; type=&#34;video/mp4&#34;&gt; There is a video here, but your browser does not support the video tag.
            &lt;/video&gt;&lt;figcaption&gt;The robot can reach the same point from multiple orientations&lt;/figcaption&gt;
        &lt;/figure&gt;
        &lt;figure&gt;
            &lt;video width=&#34;500&#34; height=&#34;600&#34;
                    muted
                    loop
                    autoplay
                controls&gt;
                &lt;source src=&#34;square_robot_arm.mp4&#34; type=&#34;video/mp4&#34;&gt;
            There is a video here, but your browser does not support the video tag.
            &lt;/video&gt;&lt;figcaption&gt;The robot maps out a square using inverse kinematics&lt;/figcaption&gt;
        &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;This project can be split into seven parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The kinematics&lt;/li&gt;
&lt;li&gt;The simulation&lt;/li&gt;
&lt;li&gt;The CAD&lt;/li&gt;
&lt;li&gt;The electronics&lt;/li&gt;
&lt;li&gt;The Pico program&lt;/li&gt;
&lt;li&gt;The server program&lt;/li&gt;
&lt;li&gt;The web interface&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;&#34;&gt;Some terminology&lt;/h2&gt;
&lt;p&gt;I refer to &amp;rsquo;links&amp;rsquo; and &amp;lsquo;joints&amp;rsquo; throughout this article - joints are the servo motors (i.e., the things that make the parts of the arm rotate (although, more generally, joints do not have to be rotational)), and links are the things that hold the joints together.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The kinematics&lt;/h2&gt;
&lt;p&gt;I learnt forward and inverse kinematics by reading chapters 2, 3, and 5 of Robot Modelling and Control by Spong, Hutchinson, and Vidyasagar. It&amp;rsquo;s a pretty good book, but doesn&amp;rsquo;t give away all the answers. The book focuses on the case of a 6DOF robot arm with a spherical wrist, which is one of the robots I added to my simulation, but the 5DOF case is slightly different. My 5DOF robot does not have the first joint in the spherical wrist, which essentially means the wrist cannot yaw independently of the base of the robot. This limits the orientations of the end-effector, but not their positions, and for many tasks, this is fine. It meant that I had to calculate the yaw as a function of the base angle, and then use the 6DOF solution. Various other edge cases and limitations, such as the fact that my robot&amp;rsquo;s motors only rotate between 0 and 180 degrees, rather than a full 360, had to be accounted for in the code.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The simulation&lt;/h2&gt;
&lt;p&gt;The simulation program uses matplotlib to plot lines representing the links of the robot arm, as well as the coordinate frames of each joint. This was my first time writing a non-trivial object-oriented program, and I learnt lots about classes in Python and structuring code in general. It makes use of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller&#34;&gt;model-view-controller&lt;/a&gt; pattern, which keeps the code nice and organised.&lt;/p&gt;
&lt;p&gt;The simulation inclues options for simulating a 3DOF elbow manipulator, which forms the basis for the 5DOF and 6DOF manipulators, as well as the two more involved options. Below are videos of the 5 and 6DOF manipulators. You can see that the difference between the two is that the wrist cannot yaw independently of the &amp;ldquo;shoulder&amp;rdquo; of the arm in the 5DOF case, which as you can see in the video, results in the 5DOF arm being more limited in its choice of orientation for a given point (the yaw is coupled to the angle of the shoulder).&lt;/p&gt;
&lt;div class=&#34;pair-figure-shortcode&#34;&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/5DOF_manipulator_sim_hu_78178a460bca635c.gif&#34; width=&#34;400&#34; height=&#34;300&#34; alt=&#34;&#34;&gt;
            &lt;figcaption&gt;&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/6DOF_manipulator_sim_hu_b0378b94b31dea2c.gif&#34; width=&#34;400&#34; height=&#34;300&#34; alt2=&#34;The 6DOF arm&#34;&gt;
            &lt;figcaption&gt;The 6DOF arm&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&#34;&#34;&gt;The CAD&lt;/h2&gt;
&lt;p&gt;The robot was designed using FreeCAD. I designed all the parts myself. While the robot works, there are a lot of things I would have done differently if I were to start over:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Figuring out a better way to manage spreadsheets - I often have to reuse certain values like the measurements of the motors, which means these values get copied over to multiple sheets&lt;/li&gt;
&lt;li&gt;More importantly, the robot is very unstable. This was my first CAD design where knowledge of mechanical design techniques (which I possess very little of) played an important role. If I was to start over, I would like to buy some better motors, ideally ones where you can connect both sides of the motor to a joint. Since I wanted this first project to be cheap, this was sort of a necessary drawback.&lt;/li&gt;
&lt;li&gt;The shoulder joint was designed to just slot into the base, this means there is a lot of wiggle, so the positions taken by the model are often off by a couple of millimetres.&lt;/li&gt;
&lt;li&gt;The claw placement currently does not follow the Denavitt-Hartenberg convention. This was not a problem, until I implemented inverse kinematics. What it means in practice is that the claw position is always slightly off from the desired position. For this reason, there aren&amp;rsquo;t any videos of the robot actually picking anything up in this article.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;pair-figure-shortcode&#34;&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/robot_arm_cad_model_hu_376a5dc76479bc70.png&#34; width=&#34;400&#34; height=&#34;400&#34; alt=&#34;CAD model of the robot arm&#34;&gt;
            &lt;figcaption&gt;CAD model of the robot arm&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/robot_arm_cad_model_alt_pos_hu_2e8fb6b295fcb0a.png&#34; width=&#34;400&#34; height=&#34;400&#34; alt2=&#34;CAD model of the robot in a different position&#34;&gt;
            &lt;figcaption&gt;CAD model of the robot in a different position&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&#34;&#34;&gt;The electronics&lt;/h2&gt;
&lt;p&gt;The electronics in this project are very simple. The robot is controlled by a Raspberry Pi Pico W which connects to a PCA9685 servo driver board via I2C. The four MG99R servos and the one MG90s servo motor are connected to and controlled by this servo driver. The Pico receives joint angles from my PC via USB, then sends the angles to the servo driver, which then moves the servos. All the wiring lives on a breadboard.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The Pico program&lt;/h2&gt;
&lt;p&gt;The Pico code is written in Micropython. Originally, both cores on the Pico were utilised, courtesy of the &lt;a href=&#34;https://docs.micropython.org/en/latest/library/_thread.html&#34;&gt;_thread&lt;/a&gt; library. Servo control was handled by core0 and networking (for communication with the server (my PC)) was handled by core1. Servo control was implemented as a callback that activated every time servo angles were sent from the server. Long polling was used: The Pico sent a HTTP GET request for angles to the server, and the server responds when they are updated. Unfortunately, this wasn&amp;rsquo;t the most reliable form of communication, and it included lots of overhead. I wanted to simplify the process using Websockets rather than long polling, but couldn&amp;rsquo;t find any decent libraries that allowed to Pico to use Websockets while acting as a client, and my networking knowledge is limited to the point where I didn&amp;rsquo;t want to write my own.&lt;/p&gt;
&lt;p&gt;My solution came in the form of an even further simplification. Since my robot and server are always next to each other anyway, I simply chose to send servo angles from my PC to the Pico over USB, using &lt;a href=&#34;https://pythonhosted.org/pyserial/&#34;&gt;pyserial&lt;/a&gt;. This made the code on the Pico much simpler, and threading was no longer needed. Now the Pico simply waits for data to be received, then moves the servos accordingly via &lt;a href=&#34;https://github.com/kevinmcaleer/pca9685_for_pico&#34;&gt;Kevin McAleer&amp;rsquo;s micropython PCA9685 library&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The server&lt;/h2&gt;
&lt;p&gt;Originally, the server used the &lt;code&gt;ThreadingHTTPServer&lt;/code&gt; class from the &lt;a href=&#34;https://docs.python.org/3/library/http.server.html&#34;&gt;http.server&lt;/a&gt; library for communication with both the web interface and the Pico. As mentioned in the last section, the Pico now receives data via USB, and with this change I also moved to using the &lt;a href=&#34;https://microdot.readthedocs.io/en/latest/&#34;&gt;Microdot&lt;/a&gt; library for communication with the web interface. This makes the code a lot more readable by hiding away all the HTTP boilerplate.&lt;/p&gt;
&lt;p&gt;The server receives data from the web server: either angles or pose. Angles are immediately sent to the Pico, whereas pose data is first passed to the inverse kinematics method of the robot arm object, different arm configurations (e.g., elbow up vs elbow down) are checked for validity, and the resulting angles are sent over to the Pico, which then moves the servos.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The web interface&lt;/h2&gt;
&lt;p&gt;The front end of the web interface is an exceedingly basic HTML file, containing only 6 sliders (for angle and claw control), some text boxes to specify position and orientation and a few buttons to submit data. Maybe I&amp;rsquo;ll add some CSS in the future.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;As I mentioned in the CAD section, this robot, while functional, leaves a lot of room for improvement. This is of no surprise, since this was my first time building a robot, and I was bound to make mistakes. Nevertheless, I am due an upgrade. Over the course of this project, I most enjoyed working on the mathematics and programming side of things, as opposed to the CAD design and electronics. With that in mind, I have decided to build a &lt;a href=&#34;https://huggingface.co/docs/lerobot/so101&#34;&gt;LeRobot SO-101&lt;/a&gt; arm for the next stage of this project (and some future projects using reinforcement learning hopefully).&lt;/p&gt;
&lt;p&gt;The next stage is the addition of a camera to the workspace, which will run an object detection algorithm written in PyTorch - I&amp;rsquo;m currently learning about convolutional neural networks. I can then use my knowledge of rigid motions (learnt from Robot Modelling and Control) to determine the position of the objects detected in the camera frame to get their coordinates in the base frame, and move the robot accordingly.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
