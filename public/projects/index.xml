<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on temperancee&#39;s website</title>
    <link>/projects/</link>
    <description>temperancee&#39;s website (Projects)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    
      

      
    

    
    <lastBuildDate>Wed, 22 Oct 2025 16:37:02 +0100</lastBuildDate>
    
    <atom:link href="/projects/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Diy Quadcopter</title>
      <link>/projects/diy_quadcopter/</link>
      <pubDate>Wed, 22 Oct 2025 16:37:02 +0100</pubDate>
      
      <guid>/projects/diy_quadcopter/</guid>
      <description>&lt;p&gt;This page documents my attempt at building a quadcopter from scratch. This includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Designing my own PCB in KiCAD&lt;/li&gt;
&lt;li&gt;Programming the ESP32S3 microcontroller on the PCB to interact with the IMU&lt;/li&gt;
&lt;li&gt;Writing a driver for said IMU in C using FreeRTOS&lt;/li&gt;
&lt;li&gt;Implementing a Kalman Filter in C using FreeRTOS to fuse the accelerometer and gyroscope data from the IMU into usable Euler angles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, this project is not complete, as I lost interest in it and switched over to working on my &lt;a href=&#34;http://localhost:1313/projects/robot_arm/&#34;&gt;robot arm&lt;/a&gt;. I did however enjoy working on the PCB design, learning about the Kalman Filter, and using FreeRTOS, so I wanted to document my work here.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Repository: &lt;a href=&#34;https://github.com/temperancee/wayfinder&#34;&gt;Wayfinder&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Like my robot arm, this project comprises many parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Kalman filter&lt;/li&gt;
&lt;li&gt;The PCB design&lt;/li&gt;
&lt;li&gt;The (very simple) driver&lt;/li&gt;
&lt;li&gt;FreeRTOS considerations&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;&#34;&gt;Sensor Fusion and the Kalman Filter&lt;/h2&gt;
&lt;p&gt;The goal of this section is simply to stabilise the quadcopter in the air, so it can hover. We can think about this as fixing the roll and pitch angles of the quadcopter to 0. Roll, pitch, and yaw angles tell us how much a body in 3D space has been rotated around each of the x, y, and z axes, as in the diagram below:&lt;/p&gt;
&lt;p&gt;We will refer to these angles as Euler angles throughout this article, although technically they are not necessarily the same - see &lt;a href=&#34;https://en.wikipedia.org/wiki/Euler_angles&#34;&gt;Euler Angles&lt;/a&gt; for more details.
We seek a way to measure the roll and pitch angles. We ignore the yaw, as we just want the drone to hover, and don&amp;rsquo;t particularly care which way it faces (and from a more practical standpoint, measuring yaw requires a &lt;a href=&#34;https://en.wikipedia.org/wiki/Magnetometer&#34;&gt;magnetometer&lt;/a&gt;, which are tricky to use, and make the drone more expensive than I need it to be). The sensor we use for this is the Intertial Measurement Unit (IMU), which is a combination of a gyroscope and an accelerometer (more expensive IMUs also include magnetometers, in which case they are called 9-axis IMUs, whereas a gyroscope and accelerometer combo is a 6-axis IMU). The gyroscope measures angular &lt;em&gt;velocity&lt;/em&gt;, and the accelerometer measures acceleration in the x, y, and z directions. These are of course, not what we want, but with a bit of maths we can turn both of these measurements into measurements of roll and pitch.&lt;/p&gt;
&lt;h3 id=&#34;&#34;&gt;Deriving roll and pitch from the accelerometer and gyroscope&lt;/h3&gt;
&lt;p&gt;Angular velocity is just the rate of change of our Euler angles, so by integrating the angular velocity of roll and pitch, we get our desired angles. We use Euler integration for this, leading us to the expression $$\phi_t = \phi_{t-1} + \phi^\prime_t\Delta t$$ where $\phi_t$ is the roll at time $t$, $\phi^\prime_t$ is the rate of change of the roll at time $t$ (this is what the gyroscope outputs), and $\Delta t$ is the time between each iteration (more on this later). We have the same equation for our pitch, $\theta$.&lt;/p&gt;
&lt;p&gt;For the accelerometer measurements, we can use trigonometry. The derivations are detailed &lt;a href=&#34;https://mwrona.com/posts/accel-roll-pitch/&#34;&gt;here&lt;/a&gt;. One thing to note about the derivation is that since we don&amp;rsquo;t care about yaw, we essentially treat all yaws of a given orientation as equal, which allows us to simplify the Euler angle rotation matrix formulae and arrive at the form used in the linked article.&lt;/p&gt;
&lt;h3 id=&#34;&#34;&gt;The Kalman Filter&lt;/h3&gt;
&lt;p&gt;I will not go into detail about how the Kalman Filter works here, but I do have an article about it: &lt;a href=&#34;http://localhost:1313/blog/kalman_filter/&#34;&gt;Kalman Filter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this context, our state is the roll and pitch of the quadcopter. These two variables sit together in a 2D vector in our equations.&lt;/p&gt;
&lt;p&gt;Applying the Kalman Filter to the problem of sensor fusion requires a seemingly odd interpretation of the control and measurement aspects of the Kalman Filter. We treat the angular velocity measurements from the gyroscope as controls, and the accelerometer-derived angle estimates as measurements. The idea here is that changing the motor speeds (what we would intuitively call the control in this situation) directly affects the angular velocity, and by setting $A_t = I, B_t = \Delta t I$, the Kalman Filter prediction formula becomes the Euler integration formula, which is why using Euler integration makes so much sense here.&lt;/p&gt;
&lt;p&gt;The measurement step proceeds as we would expect, our measurement, $z_t$ is a vector containing the roll and pitch estimates derived from our acceleromenter measurements.&lt;/p&gt;
&lt;p&gt;With the theory out of the way, we can turn to practical aspects. I initialised the variance matrices to values I found other people using for quadcopter state estimation and they seemed to work fine. The accelerometer produces measurements more infrequently than the gyroscope, so the prediction step of the Kalman Filter runs every 2ms, and the measurement step every 10ms. These steps are implemented as FreeRTOS tasks and are executed using timers.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The PCB design&lt;/h2&gt;
&lt;p&gt;I designed the PCB for the flight computer in KiCAD. Learning PCB design took a long time. I found the videos by Phil&amp;rsquo;s Lab on YouTube to be an invaluable source of knowledge. I learnt about the importance of trace widths, layers, stitching vias, (just list all the somewhat advanced things you had to learn).&lt;/p&gt;
&lt;p&gt;I also revisited some basic electronic knowledge when trying to understand the unidirectional motor circuits I used [picture]. This involved learning about MOSFETs and some basics on inductors (including flyback diodes).&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The driver&lt;/h2&gt;
&lt;p&gt;The IMU I chose to use for this project did not have a readily available Arduino driver written for it, so I endeavoured to read the data sheet and write a very minimal one myself. This was my first time writing a driver, and I found working at such a low-level of programming to be quite cool. The driver simply implements read and write functions for the IMU&amp;rsquo;s registers, an initialisation function which writes to some configuration registers on start-up, and a FreeRTOS task to read sensor data from the IMU&amp;rsquo;s accelerometer and gyroscope registers, transforming the acceleration and Euler angle rate of change units and updating the IMU struct variable with the new data (via a mutex, to protect the object from being read by another task).&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;FreeRTOS&lt;/h2&gt;
&lt;p&gt;In order to have the Kalman Filter and the planned PID loop run at the same time, I decided to use a real time operating system (RTOS) to handle scheduling the different tasks. I chose to use FreeRTOS for its simplicity, as this use case did not require a large suite of libraries like those offered by Zephyr for example. I learnt about mutexes, semaphores, queues, and timers - mutexes and timers especially were key to making sure the angle state was handled correctly, and that the Kalman Filter steps ran at the right time. This series of &lt;a href=&#34;https://www.youtube.com/playlist?list=PLUWXFeSM9LNTBX4GoapiTk_Kxs8FOPv0W&#34;&gt;videos by Shawn Hymel&lt;/a&gt; made the topic very clear and provided exercises to make sure I understood the material. I also learnt about notifications in FreeRTOS, which I used to replace the binary semaphores that were previously in my code.&lt;/p&gt;
&lt;h1 id=&#34;&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;While I abandoned this project in the end it was very fun to work on and taught me more than any previous project I had attempted. I found that I enjoyed working with FreeRTOS and writing low-level drivers, even if it made the programming side of things more complicated. Finally getting the opportunity to learn PCB design properly was great, and I reckon it will serve me well in the future, although I will try my best to avoid needing a bespoke PCB, since it did take a lot of time and effort, and it isn&amp;rsquo;t exactly cheap to get boards produced!&lt;/p&gt;
&lt;p&gt;When my next term of university begins at the start of 2026 I&amp;rsquo;ll be working on a self-balancing two-wheeled robot with another student from the Robotics Society at my university. It will require me to use my knowledge of Kalman Filters again, and will give me another opportunity to  implement a PID loop (I promise I&amp;rsquo;ll actually stick with it this time). Expect a post about that a few months from now.&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robot Arm</title>
      <link>/projects/robot_arm/</link>
      <pubDate>Fri, 15 Aug 2025 09:08:42 +0100</pubDate>
      
      <guid>/projects/robot_arm/</guid>
      <description>&lt;p&gt;This page documents my work on building a robot arm. At a glance this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deriving the inverse kinematics equations for a 5DOF robot arm, and implementing them in simulation and on hardware, handling various edge cases and hardware limitations&lt;/li&gt;
&lt;li&gt;Writing a simulator in matplotlib for not only the 5DOF arm but also a 6DOF arm&lt;/li&gt;
&lt;li&gt;Designing the arm in FreeCAD and 3D printing it&lt;/li&gt;
&lt;li&gt;Using a Raspberry Pi Pico W to control the servo motors and communicate with the web server&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Repositories: &lt;a href=&#34;https://github.com/temperancee/robot_arm&#34;&gt;Robot Arm&lt;/a&gt;, &lt;a href=&#34;https://github.com/temperancee/robot_arm_kinematics_simulation&#34;&gt;Simulation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;div class=&#34;pair-figure-shortcode&#34;&gt;
        &lt;figure&gt;
            &lt;video width=&#34;500&#34; height=&#34;600&#34;
                    muted
                    loop
                    autoplay
                controls&gt;
                &lt;source src=&#34;wrist_robot_arm.mp4&#34; type=&#34;video/mp4&#34;&gt; There is a video here, but your browser does not support the video tag.
            &lt;/video&gt;&lt;figcaption&gt;The robot can reach the same point from multiple orientations&lt;/figcaption&gt;
        &lt;/figure&gt;
        &lt;figure&gt;
            &lt;video width=&#34;500&#34; height=&#34;600&#34;
                    muted
                    loop
                    autoplay
                controls&gt;
                &lt;source src=&#34;square_robot_arm.mp4&#34; type=&#34;video/mp4&#34;&gt;
            There is a video here, but your browser does not support the video tag.
            &lt;/video&gt;&lt;figcaption&gt;The robot maps out a square using inverse kinematics&lt;/figcaption&gt;
        &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;This project can be split into seven parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The kinematics&lt;/li&gt;
&lt;li&gt;The simulation&lt;/li&gt;
&lt;li&gt;The CAD&lt;/li&gt;
&lt;li&gt;The electronics&lt;/li&gt;
&lt;li&gt;The Pico program&lt;/li&gt;
&lt;li&gt;The server program&lt;/li&gt;
&lt;li&gt;The web interface&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;&#34;&gt;Some terminology&lt;/h2&gt;
&lt;p&gt;I refer to &amp;rsquo;links&amp;rsquo; and &amp;lsquo;joints&amp;rsquo; throughout this article - joints are the servo motors (i.e., the things that make the parts of the arm rotate (although, more generally, joints do not have to be rotational)), and links are the things that hold the joints together.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The kinematics&lt;/h2&gt;
&lt;p&gt;I learnt forward and inverse kinematics by reading chapters 2, 3, and 5 of Robot Modelling and Control by Spong, Hutchinson, and Vidyasagar. It&amp;rsquo;s a pretty good book, but doesn&amp;rsquo;t give away all the answers. The book focuses on the case of a 6DOF robot arm with a spherical wrist, which is one of the robots I added to my simulation, but the 5DOF case is slightly different. My 5DOF robot does not have the first joint in the spherical wrist, which essentially means the wrist cannot yaw independently of the base of the robot. This limits the orientations of the end-effector, but not their positions, and for many tasks, this is fine. It meant that I had to calculate the yaw as a function of the base angle, and then use the 6DOF solution. Various other edge cases and limitations, such as the fact that my robot&amp;rsquo;s motors only rotate between 0 and 180 degrees, rather than a full 360, had to be accounted for in the code.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The simulation&lt;/h2&gt;
&lt;p&gt;The simulation program uses matplotlib to plot lines representing the links of the robot arm, as well as the coordinate frames of each joint. This was my first time writing a non-trivial object-oriented program, and I learnt lots about classes in Python and structuring code in general. It makes use of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller&#34;&gt;model-view-controller&lt;/a&gt; pattern, which keeps the code nice and organised.&lt;/p&gt;
&lt;p&gt;The simulation inclues options for simulating a 3DOF elbow manipulator, which forms the basis for the 5DOF and 6DOF manipulators, as well as the two more involved options. Below are videos of the 5 and 6DOF manipulators. You can see that the difference between the two is that the wrist cannot yaw independently of the &amp;ldquo;shoulder&amp;rdquo; of the arm in the 5DOF case, which as you can see in the video, results in the 5DOF arm being more limited in its choice of orientation for a given point (the yaw is coupled to the angle of the shoulder).&lt;/p&gt;
&lt;div class=&#34;pair-figure-shortcode&#34;&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/5DOF_manipulator_sim_hu_78178a460bca635c.gif&#34; width=&#34;400&#34; height=&#34;300&#34; alt=&#34;The 5DOF arm&#34;&gt;
            &lt;figcaption&gt;The 5DOF arm&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/6DOF_manipulator_sim_hu_b0378b94b31dea2c.gif&#34; width=&#34;400&#34; height=&#34;300&#34; alt2=&#34;The 6DOF arm&#34;&gt;
            &lt;figcaption&gt;The 6DOF arm&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&#34;&#34;&gt;The CAD&lt;/h2&gt;
&lt;p&gt;The robot was designed using FreeCAD. I designed all the parts myself. While the robot works, there are a lot of things I would have done differently if I were to start over:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Most importantly, the robot is very unstable. This was my first CAD design where knowledge of mechanical design techniques (which I possess very little of) played an important role. If I was to start over, I would like to buy some better motors, ideally ones where you can connect both sides of the motor to a joint. Since I wanted this first project to be cheap, this was sort of a necessary drawback.&lt;/li&gt;
&lt;li&gt;The shoulder joint was designed to just slot into the base, this means there is a lot of wiggle, so the positions taken by the model are often off by a couple of millimetres.&lt;/li&gt;
&lt;li&gt;The claw placement currently does not follow the Denavitt-Hartenberg convention. This was not a problem, until I implemented inverse kinematics. What it means in practice is that the claw position is always slightly off from the desired position. For this reason, there aren&amp;rsquo;t any videos of the robot actually picking anything up in this article.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;pair-figure-shortcode&#34;&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/robot_arm_cad_model_hu_376a5dc76479bc70.png&#34; width=&#34;400&#34; height=&#34;400&#34; alt=&#34;CAD model of the robot arm&#34;&gt;
            &lt;figcaption&gt;CAD model of the robot arm&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;figure&gt;
            &lt;img src=&#34;http://localhost:1313/projects/robot_arm/robot_arm_cad_model_alt_pos_hu_2e8fb6b295fcb0a.png&#34; width=&#34;400&#34; height=&#34;400&#34; alt2=&#34;CAD model of the robot in a different position&#34;&gt;
            &lt;figcaption&gt;CAD model of the robot in a different position&lt;/figcaption&gt;
        &lt;/figure&gt;&lt;/div&gt;

&lt;h2 id=&#34;&#34;&gt;The electronics&lt;/h2&gt;
&lt;p&gt;The electronics in this project are very simple. The robot is controlled by a Raspberry Pi Pico W which connects to a PCA9685 servo driver board via I2C. The four MG99R servos and the one MG90s servo motor are connected to and controlled by this servo driver. The Pico receives joint angles from my PC via USB, then sends the angles to the servo driver, which then moves the servos. All the wiring lives on a breadboard.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The Pico program&lt;/h2&gt;
&lt;p&gt;The Pico code is written in Micropython. Originally, both cores on the Pico were utilised, courtesy of the &lt;a href=&#34;https://docs.micropython.org/en/latest/library/_thread.html&#34;&gt;_thread&lt;/a&gt; library. Servo control was handled by core0 and networking (for communication with the server (my PC)) was handled by core1. Servo control was implemented as a callback that activated every time servo angles were sent from the server. Long polling was used: The Pico sent a HTTP GET request for angles to the server, and the server responds when they are updated. Unfortunately, this wasn&amp;rsquo;t the most reliable form of communication, and it included lots of overhead. I wanted to simplify the process using Websockets rather than long polling, but couldn&amp;rsquo;t find any decent libraries that allowed to Pico to use Websockets while acting as a client, and my networking knowledge is limited to the point where I didn&amp;rsquo;t want to write my own.&lt;/p&gt;
&lt;p&gt;My solution came in the form of an even further simplification. Since my robot and server are always next to each other anyway, I simply chose to send servo angles from my PC to the Pico over USB, using &lt;a href=&#34;https://pythonhosted.org/pyserial/&#34;&gt;pyserial&lt;/a&gt;. This made the code on the Pico much simpler, and threading was no longer needed. Now the Pico simply waits for data to be received, then moves the servos accordingly via &lt;a href=&#34;https://github.com/kevinmcaleer/pca9685_for_pico&#34;&gt;Kevin McAleer&amp;rsquo;s micropython PCA9685 library&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The server&lt;/h2&gt;
&lt;p&gt;Originally, the server used the &lt;code&gt;ThreadingHTTPServer&lt;/code&gt; class from the &lt;a href=&#34;https://docs.python.org/3/library/http.server.html&#34;&gt;http.server&lt;/a&gt; library for communication with both the web interface and the Pico. As mentioned in the last section, the Pico now receives data via USB, and with this change I also moved to using the &lt;a href=&#34;https://microdot.readthedocs.io/en/latest/&#34;&gt;Microdot&lt;/a&gt; library for communication with the web interface. This makes the code a lot more readable by hiding away all the HTTP boilerplate.&lt;/p&gt;
&lt;p&gt;The server receives data from the web server: either angles or pose. Angles are immediately sent to the Pico, whereas pose data is first passed to the inverse kinematics method of the robot arm object, different arm configurations (e.g., elbow up vs elbow down) are checked for validity, and the resulting angles are sent over to the Pico, which then moves the servos.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;The web interface&lt;/h2&gt;
&lt;p&gt;The front end of the web interface is an exceedingly basic HTML file, containing only 6 sliders (for angle and claw control), some text boxes to specify position and orientation and a few buttons to submit data. Maybe I&amp;rsquo;ll add some CSS in the future.&lt;/p&gt;
&lt;h2 id=&#34;&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;As I mentioned in the CAD section, this robot, while functional, leaves a lot of room for improvement. This is of no surprise, since this was my first time building a robot, and I was bound to make mistakes. Nevertheless, I am due an upgrade. Over the course of this project, I most enjoyed working on the mathematics and programming side of things, as opposed to the CAD design and electronics. With that in mind, I have decided to build a &lt;a href=&#34;https://huggingface.co/docs/lerobot/so101&#34;&gt;LeRobot SO-101&lt;/a&gt; arm for the next stage of this project (and some future projects using reinforcement learning hopefully).&lt;/p&gt;
&lt;p&gt;The next stage is the addition of a camera to the workspace, which will run an object detection algorithm written in PyTorch - I&amp;rsquo;m currently learning about convolutional neural networks. I can then use my knowledge of rigid motions (learnt from Robot Modelling and Control) to determine the position of the objects detected in the camera frame to get their coordinates in the base frame, and move the robot accordingly.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
